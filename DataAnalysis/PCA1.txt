☆StandardScaler():データセット内の特徴量（説明変数）を標準化するために使用されます。標準化は、特徴量を平均が0で標準偏差が1に変換するプロセスです。
目的: 主に、異なる尺度や単位で表される特徴量を同じ尺度に合わせ、モデルの学習や評価を改善します。また、多くの機械学習アルゴリズムは、入力特徴量が標準化されていることを前提としています。

操作: StandardScaler()を使用すると、各特徴量の平均を0にし、標準偏差を1に変換します。これにより、データの中心を原点に持っていき、散らばり具合を均一にします。

適用: 通常、データ前処理のステップとして、モデルの学習前に適用されます。


☆PCA():多次元データを低次元のデータに変換するための次元削減手法です。元の特徴量を線形結合して新しい特徴量（主成分）を生成します。

目的: 主に、高次元データセット内の情報を保持しながら、多重共線性を軽減し、モデルの解釈性を向上させることを目的とします。また、データの可視化やノイズの除去にも使用されます。→PCAがデータの特性を捉える上で有用な新しい変数（主成分）を生成するからです。
情報保持: PCAは、元のデータの分散を最大限に保持する主成分を選択します。したがって、第1主成分は元データの分散の大部分を説明し、第2主成分は残りの分散の大部分を説明します。このように、主成分は元のデータの重要な情報を保持し、不要なノイズを排除します。

操作: PCA()を使用すると、元の特徴量間の共分散行列を分析し、固有値分解を行います。固有ベクトル（主成分）は元の特徴量の組み合わせであり、固有値はそれぞれの主成分が説明する分散を示します。

適用: 通常、PCAはデータセット内の特徴量が多すぎる場合や、多重共線性の問題がある場合に適用されます。主成分分析は、元の特徴量の次元を削減し、新しい特徴量セットを生成します。

比較:

☆固有値分解：正方行列を特別な形式に分解する数学的な方法→行列が固有値と呼ばれる特別な数値とそれに関連する固有ベクトルと呼ばれる特別なベクトルに分解される
〇固有値：行列が持つ特別な数値。その行列の性質を表現する。通常λで表現。
〇固有ベクトル：対応する固有値に関連付けられる特別なベクトルで、行列の変換に対する不変な方向を示す